<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="机器学习的一般步骤是：训练样本 - 特征抽取 - 学习函数  - 预测。其中，为了使模型型获得更多训练，预测和学习函数是在不断循环的。 机器学习的问题可以分为两种类型：分类问题和预测问题。分类模型是将数据最终归于某一个类型，而预测模型的结果更多的是一个具体数值。这里先讲一讲机器学习中经典的回归算法。">
<meta property="og:type" content="article">
<meta property="og:title" content="回归算法 Regression Algorithm">
<meta property="og:url" content="http://example.com/2020/09/22/Regression-Algorithms/index.html">
<meta property="og:site_name" content="枫落的Blog">
<meta property="og:description" content="机器学习的一般步骤是：训练样本 - 特征抽取 - 学习函数  - 预测。其中，为了使模型型获得更多训练，预测和学习函数是在不断循环的。 机器学习的问题可以分为两种类型：分类问题和预测问题。分类模型是将数据最终归于某一个类型，而预测模型的结果更多的是一个具体数值。这里先讲一讲机器学习中经典的回归算法。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://math.now.sh?inline=y%5E*%20%3D%20argmax%5C%20f%28X_i%29">
<meta property="og:image" content="https://math.now.sh?inline=x_1">
<meta property="og:image" content="https://math.now.sh?inline=x_2">
<meta property="og:image" content="https://math.now.sh?inline=y">
<meta property="og:image" content="https://math.now.sh?inline=x">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="og:image" content="https://math.now.sh?inline=h_%5Ctheta%28x%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20h_%7B%5Ctheta%7D%28x%29%20%26%20%3D%20%5Ctheta_0%20%2B%20%5Ctheta_1x_1%20%2B%20%5Ctheta_2x_2%20%5C%5C%20%26%20%3D%20%5Csum_%7Bi%3D0%7D%5E%7B2%7D%5Ctheta_ix_i%20%5C%5C%20%26%20%3D%20%5Ctheta%5ETx%20%5Cend%7Baligned%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Cunderbrace%7By%5E%7B%28i%29%7D%7D_%7B%E7%9C%9F%E5%AE%9E%E5%80%BC%7D%20%3D%20%5Cunderbrace%7B%5Ctheta%5ETx%5E%7B(i)%7D%7D_%7B%E9%A2%84%E6%B5%8B%E5%80%BC%7D%20%2B%20%5Cunderbrace%7B%5Cvarepsilon%5E%7B(i)%7D%7D_%7B%E8%AF%AF%E5%B7%AE%7D%20%5Ctag%7B1%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Cvarepsilon%5E%7B%28i%29%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta%5E2">
<meta property="og:image" content="https://math.now.sh?inline=p">
<meta property="og:image" content="https://math.now.sh?inline=p">
<meta property="og:image" content="https://math.now.sh?inline=p%28%5Cvarepsilon%5E%7B(i%29%7D)%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(%5Cvarepsilon%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)">
<meta property="og:image" content="https://math.now.sh?inline=%5Cexp%28n%29%20%3D%20e%5En">
<meta property="og:image" content="https://math.now.sh?inline=%281%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cvarepsilon%5E%7B%28i%29%7D">
<meta property="og:image" content="https://math.now.sh?inline=p%28y%5E%7B(i%29%7D%7Cx%5E%7B(i)%7D%3B%5Ctheta)%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5Ctag%7B2%7D">
<meta property="og:image" content="https://math.now.sh?inline=p%28y%5E%7B(i%29%7D%7Cx%5E%7B(i)%7D%3B%5Ctheta)%20%5Cin%20%5B0%2C1%5D">
<meta property="og:image" content="https://math.now.sh?inline=p">
<meta property="og:image" content="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20L%28%5Ctheta%29%20%26%20%3D%20%5Cprod_%7Bi%3D1%7D%5E%7Bm%7Dp(y%5E%7B(i)%7D%7Cx%5E%7B(i)%7D%3B%5Ctheta)%20%5C%5C%20%26%20%3D%20%5Cprod_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5Cend%7Baligned%7D%20%5Ctag%7B3%7D">
<meta property="og:image" content="https://math.now.sh?inline=L%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=p">
<meta property="og:image" content="https://math.now.sh?inline=L%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=L%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20l%28%5Ctheta%29%20%26%20%3D%20%5Clog%20L(%5Ctheta)%20%5C%5C%20%26%20%3D%20%5Clog%20%5Cprod_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5C%5C%20%26%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Clog%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5C%5C%20%26%20%3D%20m%20%5Clog%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20-%20%5Cfrac%7B1%7D%7B%5Csigma%5E2%7D%20%5Ccdot%20%5Cfrac12%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%20%5Cend%7Baligned%7D%20%5Ctag%7B4%7D">
<meta property="og:image" content="https://math.now.sh?inline=l%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=m%20%5Clog%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="og:image" content="https://math.now.sh?inline=l%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cfrac%7B1%7D%7B%5Csigma%5E2%7D%20%5Ccdot%20%5Cfrac12%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%28y%5E%7B(i%29%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2">
<meta property="og:image" content="https://math.now.sh?inline=J%28%5Ctheta%29%20%3D%20%5Cfrac12%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)%5E2%20%5Ctag%7B5%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Cfrac12">
<meta property="og:image" content="https://math.now.sh?inline=J%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="og:image" content="https://math.now.sh?inline=%285%29">
<meta property="og:image" content="https://math.now.sh?inline=%28h_%7B%5Ctheta%7D(x%5E%7B(i%29%7D)-y%5E%7B(i)%7D)%5E2">
<meta property="og:image" content="https://math.now.sh?inline=J%28%5Ctheta%29%20%3D%20%5Cfrac12%20(X%5Ctheta-y)%5ET(X%5Ctheta-y)">
<meta property="og:image" content="https://math.now.sh?inline=J%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="og:image" content="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20%5Cnabla_%5Ctheta%20J%28%5Ctheta%29%20%26%20%3D%20%5Cnabla_%5Ctheta%20(%5Cfrac12%20(X%5Ctheta-y)%5ET(X%5Ctheta-y))%20%5C%5C%20%26%20%3D%20%5Cnabla_%5Ctheta%20(%5Cfrac12%20(%5Ctheta%5ETX%5ET-y%5ET)(X%5Ctheta-y))%20%5C%5C%20%26%20%3D%20%5Cnabla_%5Ctheta%20(%5Cfrac12%20(%5Ctheta%5ETX%5ETX%5Ctheta%20-%20%5Ctheta%5ETX%5ETy%20-%20y%5ETX%5Ctheta%20%2B%20y%5ETy))%20%5C%5C%20%26%20%3D%20%5Cfrac12%20(2X%5ETX%5Ctheta%20-%20X%5ETy%20-%20(y%5ETX)%5ET)%20%5C%5C%20%26%20%3D%20X%5ETX%5Ctheta%20-%20X%5ETy%20%5Cend%7Baligned%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Cnabla_%5Ctheta%20J%28%5Ctheta%29%3D0">
<meta property="og:image" content="https://math.now.sh?inline=X%5ETX%5Ctheta%20-%20X%5ETy%3D0">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta%20%3D%20%28X%5ETX%29%5E%7B-1%7DX%5ETy%20%5Ctag%7B6%7D">
<meta property="og:image" content="http://example.com/2020/09/22/Regression-Algorithms/790418-20181107181130984-1052306153.png">
<meta property="og:image" content="https://math.now.sh?inline=g%28z%29%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7B(-z)%7D%7D">
<meta property="og:image" content="https://math.now.sh?inline=x%20%5Cin%20%28-%5Cinfty%2C%2B%5Cinfty%29%2C%5C%20y%20%5Cin%20(0%2C1)">
<meta property="og:image" content="https://math.now.sh?inline=%280%2C1%29">
<meta property="og:image" content="https://math.now.sh?inline=h_%5Ctheta%28x%29%20%3D%20g(%5Ctheta%5ETx)%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Ctheta%5ETx%7D%7D">
<meta property="og:image" content="https://math.now.sh?inline=h_%5Ctheta%28x%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="og:image" content="https://math.now.sh?inline=h_%5Ctheta%28x%29%3D%5Ctheta_1x%2B%5Ctheta_0">
<meta property="og:image" content="https://math.now.sh?inline=J%28%5Ctheta_0%2C%5Ctheta_1%29%20%3D%20%5Cfrac%7B1%7D%7B2m%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)%5E2">
<meta property="og:image" content="https://math.now.sh?inline=%5Cfrac1m">
<meta property="og:image" content="https://math.now.sh?inline=J%28%5Ctheta%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta_0">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta_1">
<meta property="og:image" content="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_0%7D%20%3D%20%5Cfrac1m%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)">
<meta property="og:image" content="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_1%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)%20*%20x%5E%7B(i)%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Calpha">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta_0%20%3A%3D%20%5Ctheta_0%20-%20%5Calpha%20*%20%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_0%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta_1%20%3A%3D%20%5Ctheta_1%20-%20%5Calpha%20*%20%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_1%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Calpha">
<meta property="og:image" content="https://math.now.sh?inline=%5Ctheta">
<meta property="article:published_time" content="2020-09-22T07:43:39.000Z">
<meta property="article:modified_time" content="2020-09-23T12:42:52.692Z">
<meta property="article:author" content="枫落">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="linear regression">
<meta property="article:tag" content="logistic regression">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://math.now.sh?inline=y%5E*%20%3D%20argmax%5C%20f%28X_i%29">

<link rel="canonical" href="http://example.com/2020/09/22/Regression-Algorithms/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>回归算法 Regression Algorithm | 枫落的Blog</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?fd6136b2c1ea18e60ce07ae90773a316";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">枫落的Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/09/22/Regression-Algorithms/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="枫落">
      <meta itemprop="description" content="faple_ml@163.com">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫落的Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          回归算法 Regression Algorithm
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-22 15:43:39" itemprop="dateCreated datePublished" datetime="2020-09-22T15:43:39+08:00">2020-09-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-23 20:42:52" itemprop="dateModified" datetime="2020-09-23T20:42:52+08:00">2020-09-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>机器学习的一般步骤是：训练样本 - 特征抽取 - 学习函数 <img src="https://math.now.sh?inline=y%5E*%20%3D%20argmax%5C%20f%28X_i%29" style="display:inline-block;margin: 0;"> - 预测。其中，为了使模型型获得更多训练，预测和学习函数是在不断循环的。</p>
<p>机器学习的问题可以分为两种类型：<strong>分类问题 </strong> 和<strong>预测问题</strong>。分类模型是将数据最终归于某一个类型，而预测模型的结果更多的是一个具体数值。这里先讲一讲机器学习中经典的回归算法。</p>
<a id="more"></a>
<h2 id="线性回归">线性回归</h2>
<p>我们用一个例子来展现线性回归的建模过程。下表是一个银行判断用户贷款额度的数据集，其中，银行给用户的贷款额度取决于两个因素：工资和年龄，这两个因素就是这个数据集的_特征_。</p>
<table>
<thead>
<tr>
<th>工资（<img src="https://math.now.sh?inline=x_1" style="display:inline-block;margin: 0;">）</th>
<th>年龄（<img src="https://math.now.sh?inline=x_2" style="display:inline-block;margin: 0;">）</th>
<th>额度（<img src="https://math.now.sh?inline=y" style="display:inline-block;margin: 0;">）</th>
</tr>
</thead>
<tbody>
<tr>
<td>4000</td>
<td>25</td>
<td>20000</td>
</tr>
<tr>
<td>8000</td>
<td>30</td>
<td>70000</td>
</tr>
<tr>
<td>5000</td>
<td>28</td>
<td>35000</td>
</tr>
<tr>
<td>7500</td>
<td>33</td>
<td>50000</td>
</tr>
<tr>
<td>12000</td>
<td>40</td>
<td>85000</td>
</tr>
</tbody>
</table>
<h3 id="建立模型">建立模型</h3>
<p>根据上表，给每个特征 <img src="https://math.now.sh?inline=x" style="display:inline-block;margin: 0;"> 一个参数 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;">，构成根据特征预测出的额度 <img src="https://math.now.sh?inline=h_%5Ctheta%28x%29" style="display:inline-block;margin: 0;">：</p>
<p><img src="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20h_%7B%5Ctheta%7D%28x%29%20%26%20%3D%20%5Ctheta_0%20%2B%20%5Ctheta_1x_1%20%2B%20%5Ctheta_2x_2%20%5C%5C%20%26%20%3D%20%5Csum_%7Bi%3D0%7D%5E%7B2%7D%5Ctheta_ix_i%20%5C%5C%20%26%20%3D%20%5Ctheta%5ETx%20%5Cend%7Baligned%7D" style="display:inline-block;margin: 0;"></p>
<p>但是预测的额度与真实值之间可能会有一定的误差，于是真实的额度可以表示为</p>
<p><img src="https://math.now.sh?inline=%5Cunderbrace%7By%5E%7B%28i%29%7D%7D_%7B%E7%9C%9F%E5%AE%9E%E5%80%BC%7D%20%3D%20%5Cunderbrace%7B%5Ctheta%5ETx%5E%7B(i)%7D%7D_%7B%E9%A2%84%E6%B5%8B%E5%80%BC%7D%20%2B%20%5Cunderbrace%7B%5Cvarepsilon%5E%7B(i)%7D%7D_%7B%E8%AF%AF%E5%B7%AE%7D%20%5Ctag%7B1%7D" style="display:inline-block;margin: 0;"></p>
<p>其中误差 <img src="https://math.now.sh?inline=%5Cvarepsilon%5E%7B%28i%29%7D" style="display:inline-block;margin: 0;"> 是_独立_（样本直接无关联）且_具有相同分布_（大部分误差在一个范围中）的，通常被认为服从均值为 0、方差为 <img src="https://math.now.sh?inline=%5Ctheta%5E2" style="display:inline-block;margin: 0;"> 的 <strong> 高斯分布</strong></p>
<ul>
<li>
<p>假设误差分布为 <img src="https://math.now.sh?inline=p" style="display:inline-block;margin: 0;"> （即 <img src="https://math.now.sh?inline=p" style="display:inline-block;margin: 0;"> 为高斯分布（均值为 0））</p>
<p><img src="https://math.now.sh?inline=p%28%5Cvarepsilon%5E%7B(i%29%7D)%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(%5Cvarepsilon%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)" style="display:inline-block;margin: 0;"></p>
<p>其中 <img src="https://math.now.sh?inline=%5Cexp%28n%29%20%3D%20e%5En" style="display:inline-block;margin: 0;"></p>
<p>用公式 <img src="https://math.now.sh?inline=%281%29" style="display:inline-block;margin: 0;"> 替换误差 <img src="https://math.now.sh?inline=%5Cvarepsilon%5E%7B%28i%29%7D" style="display:inline-block;margin: 0;">，得到</p>
<p><img src="https://math.now.sh?inline=p%28y%5E%7B(i%29%7D%7Cx%5E%7B(i)%7D%3B%5Ctheta)%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5Ctag%7B2%7D" style="display:inline-block;margin: 0;"></p>
<p>这里 <img src="https://math.now.sh?inline=p%28y%5E%7B(i%29%7D%7Cx%5E%7B(i)%7D%3B%5Ctheta)%20%5Cin%20%5B0%2C1%5D" style="display:inline-block;margin: 0;">，即 <img src="https://math.now.sh?inline=p" style="display:inline-block;margin: 0;"> 为概率值，它越接近 1，概率越大，预测值越接近真实值。</p>
</li>
</ul>
<h4 id="似然函数和目标函数">似然函数和目标函数</h4>
<p>我们希望每个预测值都尽量接近真实值，所以构造了 <strong> 似然函数</strong>：</p>
<p><img src="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20L%28%5Ctheta%29%20%26%20%3D%20%5Cprod_%7Bi%3D1%7D%5E%7Bm%7Dp(y%5E%7B(i)%7D%7Cx%5E%7B(i)%7D%3B%5Ctheta)%20%5C%5C%20%26%20%3D%20%5Cprod_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5Cend%7Baligned%7D%20%5Ctag%7B3%7D" style="display:inline-block;margin: 0;"></p>
<p>这里_累乘所有样本的概率值，目标是使 <img src="https://math.now.sh?inline=L%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 尽可能大_。（因为如果每个训练样本的预测值都接近真实值，即误差很小，那么每个概率 <img src="https://math.now.sh?inline=p" style="display:inline-block;margin: 0;"> 都会接近 1，于是它们的累乘也会接近 1。）</p>
<p>为了方便计算，我们将 <img src="https://math.now.sh?inline=L%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 中的乘法转换成加法运算，即对 <img src="https://math.now.sh?inline=L%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 做对数运算，得到 <strong> 对数似然函数</strong>：</p>
<p><img src="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20l%28%5Ctheta%29%20%26%20%3D%20%5Clog%20L(%5Ctheta)%20%5C%5C%20%26%20%3D%20%5Clog%20%5Cprod_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5C%5C%20%26%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Clog%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20%5Cexp(-%5Cfrac%7B(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%7D%7B2%5Csigma%5E2%7D)%20%5C%5C%20%26%20%3D%20m%20%5Clog%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20-%20%5Cfrac%7B1%7D%7B%5Csigma%5E2%7D%20%5Ccdot%20%5Cfrac12%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20(y%5E%7B(i)%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2%20%5Cend%7Baligned%7D%20%5Ctag%7B4%7D" style="display:inline-block;margin: 0;"></p>
<p>因为 <img src="https://math.now.sh?inline=l%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 的前半部分 <img src="https://math.now.sh?inline=m%20%5Clog%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D" style="display:inline-block;margin: 0;"> 为常数，不会被 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;"> 改变，所以要使 <img src="https://math.now.sh?inline=l%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 尽可能大，它的后半部分 <img src="https://math.now.sh?inline=%5Cfrac%7B1%7D%7B%5Csigma%5E2%7D%20%5Ccdot%20%5Cfrac12%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%28y%5E%7B(i%29%7D-%5Ctheta%5ETx%5E%7B(i)%7D)%5E2" style="display:inline-block;margin: 0;"> 需要尽可能小（这里后半部分一定大于 0，所以需要使其尽可能接近 0）。最后得到 <strong> 目标函数</strong></p>
<p><img src="https://math.now.sh?inline=J%28%5Ctheta%29%20%3D%20%5Cfrac12%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)%5E2%20%5Ctag%7B5%7D" style="display:inline-block;margin: 0;"></p>
<p>（留下 <img src="https://math.now.sh?inline=%5Cfrac12" style="display:inline-block;margin: 0;"> 方便求导）</p>
<h4 id="求导">求导</h4>
<p>我们的目标是找到_使 <img src="https://math.now.sh?inline=J%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 尽可能小的 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;"> 值_。对一个函数取极值，可以对其进行求导。</p>
<p>我们用矩阵形式表示 <img src="https://math.now.sh?inline=%285%29" style="display:inline-block;margin: 0;"> 中 <img src="https://math.now.sh?inline=%28h_%7B%5Ctheta%7D(x%5E%7B(i%29%7D)-y%5E%7B(i)%7D)%5E2" style="display:inline-block;margin: 0;">：</p>
<p><img src="https://math.now.sh?inline=J%28%5Ctheta%29%20%3D%20%5Cfrac12%20(X%5Ctheta-y)%5ET(X%5Ctheta-y)" style="display:inline-block;margin: 0;"></p>
<p>为了求 <img src="https://math.now.sh?inline=J%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 的极值，需要对 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;"> <em>求偏导</em></p>
<p><img src="https://math.now.sh?inline=%5Cbegin%7Baligned%7D%20%5Cnabla_%5Ctheta%20J%28%5Ctheta%29%20%26%20%3D%20%5Cnabla_%5Ctheta%20(%5Cfrac12%20(X%5Ctheta-y)%5ET(X%5Ctheta-y))%20%5C%5C%20%26%20%3D%20%5Cnabla_%5Ctheta%20(%5Cfrac12%20(%5Ctheta%5ETX%5ET-y%5ET)(X%5Ctheta-y))%20%5C%5C%20%26%20%3D%20%5Cnabla_%5Ctheta%20(%5Cfrac12%20(%5Ctheta%5ETX%5ETX%5Ctheta%20-%20%5Ctheta%5ETX%5ETy%20-%20y%5ETX%5Ctheta%20%2B%20y%5ETy))%20%5C%5C%20%26%20%3D%20%5Cfrac12%20(2X%5ETX%5Ctheta%20-%20X%5ETy%20-%20(y%5ETX)%5ET)%20%5C%5C%20%26%20%3D%20X%5ETX%5Ctheta%20-%20X%5ETy%20%5Cend%7Baligned%7D" style="display:inline-block;margin: 0;"></p>
<p>令 <img src="https://math.now.sh?inline=%5Cnabla_%5Ctheta%20J%28%5Ctheta%29%3D0" style="display:inline-block;margin: 0;">，即 <img src="https://math.now.sh?inline=X%5ETX%5Ctheta%20-%20X%5ETy%3D0" style="display:inline-block;margin: 0;">，则</p>
<p><img src="https://math.now.sh?inline=%5Ctheta%20%3D%20%28X%5ETX%29%5E%7B-1%7DX%5ETy%20%5Ctag%7B6%7D" style="display:inline-block;margin: 0;"></p>
<h2 id="Logistic- 回归">Logistic 回归</h2>
<p>逻辑回归是一个分类算法。</p>
<h3 id="S- 函数（Sigmoid- 函数）">S 函数（Sigmoid 函数）</h3>
<p><img src="/2020/09/22/Regression-Algorithms/790418-20181107181130984-1052306153.png" alt="img"></p>
<ul>
<li>
<p>函数表达式为 <img src="https://math.now.sh?inline=g%28z%29%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7B(-z)%7D%7D" style="display:inline-block;margin: 0;"></p>
</li>
<li>
<p>取值范围 <img src="https://math.now.sh?inline=x%20%5Cin%20%28-%5Cinfty%2C%2B%5Cinfty%29%2C%5C%20y%20%5Cin%20(0%2C1)" style="display:inline-block;margin: 0;"></p>
</li>
</ul>
<h4 id="建模">建模</h4>
<p>由 S 函数可以看出，逻辑回归就是把模型的计算结果映射在 S 函数上，使最终结果在 <img src="https://math.now.sh?inline=%280%2C1%29" style="display:inline-block;margin: 0;"> 区间上。我们可以设置 0.5 为分界，结果小于 0.5 的数据归于一类，大于 0.5 的归于一类。</p>
<p>令<br>
<img src="https://math.now.sh?inline=h_%5Ctheta%28x%29%20%3D%20g(%5Ctheta%5ETx)%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Ctheta%5ETx%7D%7D" style="display:inline-block;margin: 0;"><br>
这里符号含义同上，即 <img src="https://math.now.sh?inline=h_%5Ctheta%28x%29" style="display:inline-block;margin: 0;"> 是预测值。</p>
<p>之后建立目标函数的步骤与线性回归一致。</p>
<h3 id="梯度下降">梯度下降</h3>
<p>参数 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;"> 是无法一步优化到位的，我们需要一步一步使 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;"> 向函数的“坡下”走，这个向下走的“方向”就是函数在当前位置对 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;"> 的偏导数。</p>
<p>假设数据集只有一个特征，则预测值为 <img src="https://math.now.sh?inline=h_%5Ctheta%28x%29%3D%5Ctheta_1x%2B%5Ctheta_0" style="display:inline-block;margin: 0;"></p>
<p>目标函数为</p>
<p><img src="https://math.now.sh?inline=J%28%5Ctheta_0%2C%5Ctheta_1%29%20%3D%20%5Cfrac%7B1%7D%7B2m%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)%5E2" style="display:inline-block;margin: 0;"></p>
<p>（这里如果不乘 <img src="https://math.now.sh?inline=%5Cfrac1m" style="display:inline-block;margin: 0;">，意味着训练样本越多 <img src="https://math.now.sh?inline=J%28%5Ctheta%29" style="display:inline-block;margin: 0;"> 越大）</p>
<p>对 <img src="https://math.now.sh?inline=%5Ctheta_0" style="display:inline-block;margin: 0;"> 和 <img src="https://math.now.sh?inline=%5Ctheta_1" style="display:inline-block;margin: 0;"> 分别求偏导</p>
<p><img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_0%7D%20%3D%20%5Cfrac1m%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)" style="display:inline-block;margin: 0;"></p>
<p><img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_1%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D(h_%7B%5Ctheta%7D(x%5E%7B(i)%7D)-y%5E%7B(i)%7D)%20*%20x%5E%7B(i)%7D" style="display:inline-block;margin: 0;"></p>
<p>使每个参数沿梯度下降方向前进 <img src="https://math.now.sh?inline=%5Calpha" style="display:inline-block;margin: 0;"> 步</p>
<p><img src="https://math.now.sh?inline=%5Ctheta_0%20%3A%3D%20%5Ctheta_0%20-%20%5Calpha%20*%20%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_0%7D" style="display:inline-block;margin: 0;"></p>
<p><img src="https://math.now.sh?inline=%5Ctheta_1%20%3A%3D%20%5Ctheta_1%20-%20%5Calpha%20*%20%5Cfrac%7B%5Cpartial%20J%28%5Ctheta_0%2C%5Ctheta_1%29%7D%7B%5Cpartial%20%5Ctheta_1%7D" style="display:inline-block;margin: 0;"></p>
<p>这里 <img src="https://math.now.sh?inline=%5Calpha" style="display:inline-block;margin: 0;"> 称为 <strong> 学习率</strong>（或步长），步长过大可能略过最优点，步长太小迭代速度太慢。</p>
<p>当参数经过迭代后改变很小时，迭代结束，我们认为当前 <img src="https://math.now.sh?inline=%5Ctheta" style="display:inline-block;margin: 0;"> 是（或近似）最优解。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
              <a href="/tags/linear-regression/" rel="tag"># linear regression</a>
              <a href="/tags/logistic-regression/" rel="tag"># logistic regression</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/2020/09/23/Decision-Tree/" rel="next" title="决策树 Decision Tree">
      决策树 Decision Tree <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.</span> <span class="nav-text">线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.1.</span> <span class="nav-text">建立模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0%E5%92%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0"><span class="nav-number">1.1.1.</span> <span class="nav-text">似然函数和目标函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B1%82%E5%AF%BC"><span class="nav-number">1.1.2.</span> <span class="nav-text">求导</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistic-%20%E5%9B%9E%E5%BD%92"><span class="nav-number">2.</span> <span class="nav-text">Logistic 回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#S-%20%E5%87%BD%E6%95%B0%EF%BC%88Sigmoid-%20%E5%87%BD%E6%95%B0%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">S 函数（Sigmoid 函数）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E6%A8%A1"><span class="nav-number">2.1.1.</span> <span class="nav-text">建模</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.2.</span> <span class="nav-text">梯度下降</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="枫落"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">枫落</p>
  <div class="site-description" itemprop="description">faple_ml@163.com</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">枫落</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
